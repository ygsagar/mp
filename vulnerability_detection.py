# from flask import Flask, request, jsonify
# from transformers import RobertaTokenizer, RobertaForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained CodeBERT model and tokenizer
# model_name = "microsoft/codebert-base"
# tokenizer = RobertaTokenizer.from_pretrained(model_name)
# model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Prediction function
# def predict_vulnerability(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction
#     predicted_class, probabilities = predict_vulnerability(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)




# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained VulBERTa-MLP-VulDeePecker model and tokenizer
# model_name = "claudios/VulBERTa-MLP-VulDeePecker"
# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
# model = AutoModelForSequenceClassification.from_pretrained(model_name, trust_remote_code=True)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Prediction function
# def predict_vulnerability(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction
#     predicted_class, probabilities = predict_vulnerability(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)





# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import logging
# from radon.complexity import cc_visit

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained VulBERTa-MLP-VulDeePecker model and tokenizer
# model_name = "claudios/VulBERTa-MLP-VulDeePecker"
# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
# model = AutoModelForSequenceClassification.from_pretrained(model_name, trust_remote_code=True)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Cyclomatic complexity extractor using Radon
# def get_cyclomatic_complexity(code):
#     blocks = cc_visit(code)
#     complexity = sum([block.complexity for block in blocks])  # Total cyclomatic complexity
#     return complexity

# # Function to predict vulnerability using VulBERTa model
# def predict_vulnerability(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)

#     # Run the inputs through the model
#     with torch.no_grad():
#         outputs = model(**inputs)
#         logits = outputs.logits

#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Line-level analysis function
# def line_level_analysis(code):
#     lines = code.split('\n')
#     line_predictions = []
    
#     for line in lines:
#         if line.strip():  # Ignore empty lines
#             predicted_class, _ = predict_vulnerability(line)
#             line_predictions.append(predicted_class)
    
#     # Aggregate the predictions using majority voting
#     aggregated_prediction = 1 if sum(line_predictions) > len(line_predictions) / 2 else 0
#     return aggregated_prediction

# # Prediction function combining VulBERTa with static features
# def predict_vulnerability_with_features(code):
#     # Get the VulBERTa prediction
#     predicted_class_vulberta, probabilities = predict_vulnerability(code)
    
#     # Get cyclomatic complexity
#     cyclomatic_complexity = get_cyclomatic_complexity(code)
    
#     # Perform line-level analysis
#     line_level_prediction = line_level_analysis(code)
    
#     # Combine features (example simple rule-based model using mean of features)
#     combined_features = torch.tensor([predicted_class_vulberta, cyclomatic_complexity, line_level_prediction], dtype=torch.float)
    
#     # Example final prediction logic (can replace with a learned classifier)
#     final_prediction = 1 if combined_features.mean() > 0.5 else 0

#     return final_prediction, probabilities, cyclomatic_complexity, line_level_prediction

# # Define the API route for vulnerability prediction
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if 'code' is in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction with additional features
#     final_prediction, probabilities, complexity, line_prediction = predict_vulnerability_with_features(code)
    
#     # Log the prediction results
#     logging.info(f'Final prediction: {final_prediction}, VulBERTa probabilities: {probabilities}, '
#                  f'Cyclomatic Complexity: {complexity}, Line-Level Prediction: {line_prediction}')
    
#     # Return the result as JSON
#     return jsonify({
#         'vulnerability': 'Vulnerable' if final_prediction == 1 else 'Safe',
#         'vulberta_probabilities': probabilities,
#         'cyclomatic_complexity': complexity,
#         'line_level_prediction': line_prediction
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)


#24.10.2024

# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load a pretrained model that has been fine-tuned on vulnerability detection
# model_name = "microsoft/codebert-base-mlm"  # Or a suitable vulnerability-detection model
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForSequenceClassification.from_pretrained(model_name)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Function to predict whether the code contains SQL injection vulnerability
# def predict_sql_injection(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)

#     # Run the inputs through the model
#     with torch.no_grad():
#         outputs = model(**inputs)
#         logits = outputs.logits

#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route for vulnerability prediction
# @app.route('/detect_sql_injection', methods=['POST'])
# def detect_sql_injection():
#     # Check if 'code' is in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for SQL injection detection: {code}')
    
#     # Get the SQL injection prediction
#     predicted_class, probabilities = predict_sql_injection(code)
    
#     # Log the prediction results
#     logging.info(f'SQL injection prediction: {predicted_class}, Probabilities: {probabilities}')
    
#     # Return the result as JSON
#     return jsonify({
#         'sql_injection': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)





# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load a pretrained model that has been fine-tuned on vulnerability detection (CWE groups)
# model_name = "mcanoglu/microsoft-codebert-base-finetuned-defect-cwe-group-detection"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForSequenceClassification.from_pretrained(model_name)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Function to predict whether the code contains any vulnerability
# def predict_vulnerability(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512, clean_up_tokenization_spaces=True)

#     # Run the inputs through the model
#     with torch.no_grad():
#         outputs = model(**inputs)
#         logits = outputs.logits

#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route for vulnerability prediction
# @app.route('/detect_vulnerability', methods=['POST'])
# def detect_vulnerability():
#     # Check if 'code' is in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for vulnerability detection: {code}')
    
#     # Get the vulnerability prediction
#     predicted_class, probabilities = predict_vulnerability(code)
    
#     # Log the prediction results
#     logging.info(f'Vulnerability prediction: {predicted_class}, Probabilities: {probabilities}')
    
#     # Return the result as JSON
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)
















# import torch
# import torch.nn as nn
# from transformers import AutoModel, AutoTokenizer
# from torch_geometric.nn import GCNConv
# from torch_geometric.data import Data

# # Graph Neural Network class
# class GraphNetwork(nn.Module):
#     def __init__(self, num_features):
#         super(GraphNetwork, self).__init__()
#         self.conv1 = GCNConv(num_features, 64)
#         self.conv2 = GCNConv(64, 32)
#         self.fc = nn.Linear(32, 16)
#         self.relu = nn.ReLU()

#     def forward(self, x, edge_index):
#         x = self.conv1(x, edge_index)
#         x = self.relu(x)
#         x = self.conv2(x, edge_index)
#         x = self.relu(x)
#         x = self.fc(x)
#         return x

# # Enhanced model class combining Transformer and GNN
# class EnhancedVulnerabilityModel(nn.Module):
#     def __init__(self, model_name, num_classes):
#         super(EnhancedVulnerabilityModel, self).__init__()
#         self.transformer = AutoModel.from_pretrained(model_name)
#         self.graph_network = GraphNetwork(num_features=self.transformer.config.hidden_size)
#         self.fc1 = nn.Linear(self.transformer.config.hidden_size + 16, 128)
#         self.relu = nn.ReLU()
#         self.fc2 = nn.Linear(128, num_classes)
#         self.dropout = nn.Dropout(0.3)

#     def forward(self, input_ids, attention_mask, graph_data):
#         # Get transformer outputs
#         transformer_output = self.transformer(input_ids, attention_mask=attention_mask)
#         hidden_states = transformer_output[0]

#         # Use the [CLS] token representation for classification
#         cls_output = hidden_states[:, 0, :]

#         # Process graph data through GNN
#         graph_output = self.graph_network(graph_data.x, graph_data.edge_index)

#         # Combine outputs
#         combined_output = torch.cat((cls_output, graph_output.mean(dim=0)), dim=1)

#         # Fully connected layers
#         x = self.fc1(combined_output)
#         x = self.relu(x)
#         x = self.dropout(x)
#         x = self.fc2(x)

#         return x

# # Main execution
# if __name__ == "__main__":
#     model_name = "claudios/VulBERTa-MLP-VulDeePecker"  # Transformer model name
#     num_classes = 2  # Vulnerable vs. Safe
#     model = EnhancedVulnerabilityModel(model_name, num_classes)

#     # Initialize tokenizer
#     tokenizer = AutoTokenizer.from_pretrained(model_name)

#     # Example code snippet for testing
#     sample_code = "SELECT * FROM users WHERE id = '1' OR '1'='1'; --"
#     inputs = tokenizer(sample_code, return_tensors='pt', padding=True, truncation=True)

#     # Create mock graph data for demonstration
#     # (You should replace this with actual graph construction based on your code structure)
#     num_nodes = 10  # Example number of nodes in the graph
#     graph_data = Data(
#         x=torch.rand(num_nodes, model.transformer.config.hidden_size),  # Random node features
#         edge_index=torch.tensor([[0, 1, 2, 0], [1, 0, 0, 2]], dtype=torch.long)  # Simple edges
#     )

#     # Forward pass
#     model.eval()  # Set the model to evaluation mode
#     with torch.no_grad():
#         output = model(inputs['input_ids'], inputs['attention_mask'], graph_data)

#     print("Output logits:", output)  # Print raw logits
#     predicted_class = torch.argmax(output, dim=1).item()
#     print("Predicted class:", "Vulnerable" if predicted_class == 1 else "Safe")




# my main code sql injection
# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained MobileBERT SQL injection detection model and tokenizer
# model_name = "cssupport/mobilebert-sql-injection-detect"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForSequenceClassification.from_pretrained(model_name)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Prediction function
# def predict_sql_injection(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction
#     predicted_class, probabilities = predict_sql_injection(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)




## sql multiline
# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained MobileBERT SQL injection detection model and tokenizer
# model_name = "cssupport/mobilebert-sql-injection-detect"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForSequenceClassification.from_pretrained(model_name)

# # Disable gradient calculation for inference
# torch.no_grad()

# # Prediction function
# def predict_sql_injection(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
    
#     # Ensure that multi-line code is properly handled
#     if isinstance(code, list):  # If received as list of lines, combine them
#         code = '\n'.join(code)
    
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction
#     predicted_class, probabilities = predict_sql_injection(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)


#codeastra
# from peft import PeftModel, PeftConfig
# from transformers import AutoModelForCausalLM, AutoTokenizer,LlamaTokenizer
# import torch
# import logging
# from flask import Flask, request, jsonify

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained CodeAstra model and tokenizer
# config = PeftConfig.from_pretrained("rootxhacker/CodeAstra-7B")
# base_model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2")
# model = PeftModel.from_pretrained(base_model, "rootxhacker/CodeAstra-7B")
# # tokenizer = AutoTokenizer.from_pretrained("rootxhacker/CodeAstra-7B")
# tokenizer = LlamaTokenizer.from_pretrained("rootxhacker/CodeAstra-7B")

# # Disable gradient calculation for inference
# torch.no_grad()

# # Prediction function for CodeAstra
# def predict_code_astra(input_code):
#     # Tokenize the input code
#     inputs = tokenizer(input_code, return_tensors="pt", padding=True, truncation=True, max_length=512)

#     # Run the inputs through the model
#     outputs = model.generate(**inputs, max_length=150)  # Adjust max_length based on expected output

#     # Decode the generated output
#     output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

#     return output_text

# # Define the API route
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400

#     # Get the code from the request
#     code = request.json['code']

#     # Ensure that multi-line code is properly handled
#     if isinstance(code, list):  # If received as list of lines, combine them
#         code = '\n'.join(code)

#     logging.info(f'Received code for prediction: {code}')

#     # Get the prediction from CodeAstra
#     output_text = predict_code_astra(code)

#     # Log the prediction result
#     logging.info(f'Prediction output: {output_text}')

#     return jsonify({
#         'output': output_text
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)

#codeastra - 2
# import torch
# from peft import PeftModel, PeftConfig
# from transformers import AutoModelForCausalLM, AutoTokenizer
# from flask import Flask, request, jsonify
# import logging
# import bitsandbytes as bnb

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the model and tokenizer
# peft_model_id = "rootxhacker/CodeAstra-7B"
# config = PeftConfig.from_pretrained(peft_model_id)
# model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, device_map='auto')
# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)

# # Load the LoRA model
# model = PeftModel.from_pretrained(model, peft_model_id)


# # Function to generate code analysis
# def get_completion(query, model, tokenizer):
#     inputs = tokenizer(query, return_tensors="pt")
#     outputs = model.generate(**inputs, max_new_tokens=512, do_sample=True, temperature=0.7)
#     return tokenizer.decode(outputs[0], skip_special_tokens=True)

# # Define the API route
# @app.route('/analyze_code', methods=['POST'])
# def analyze_code():
#     # Check if code is provided
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400

#     # Get the code to analyze from the request
#     code_to_analyze = request.json['code']
    
#     # Handle multi-line code
#     if isinstance(code_to_analyze, list):
#         code_to_analyze = '\n'.join(code_to_analyze)
    
#     logging.info(f'Received code for analysis: {code_to_analyze}')

#     # Generate the query for the model
#     query = f"Analyze this code for vulnerabilities and quality issues:\n{code_to_analyze}"
#     result = get_completion(query, model, tokenizer)

#     # Log and return the result
#     logging.info(f'Analysis result: {result}')
#     return jsonify({'analysis': result})

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)


## for python complete code
#######################################--------------------###############################3
# from flask import Flask, request, jsonify
# from transformers import MobileBertTokenizer, MobileBertForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained MobileBERT model and tokenizer
# model_name = "cssupport/mobilebert-sql-injection-detect"
# tokenizer = MobileBertTokenizer.from_pretrained(model_name)
# model = MobileBertForSequenceClassification.from_pretrained(model_name)

# # Move the model to evaluation mode
# model.eval()

# # Function to predict SQL injection
# def predict_sql_injection(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     with torch.no_grad():
#         outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     return predicted_class, probabilities[0].tolist()

# # Define the API route for prediction
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction from the model
#     predicted_class, probabilities = predict_sql_injection(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)

##############################################3-------------------------------#################3333



##october

# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch

# # Initialize Flask app
# app = Flask(__name__)

# # Load the VulBERTa model and tokenizer with trust_remote_code=True
# model_name = "claudios/VulBERTa-MLP-VulDeePecker"
# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
# model = AutoModelForSequenceClassification.from_pretrained(model_name, trust_remote_code=True)

# # Disable gradient calculation for inference
# torch.no_grad()

# def detect_vulnerability(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Get model predictions
#     outputs = model(**inputs)
#     logits = outputs.logits
    
#     # Get predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(logits, dim=1).item()
    
#     return predicted_class

# @app.route('/detect_vulnerability', methods=['POST'])
# def detect():
#     if 'code' not in request.json:
#         return jsonify({'error': 'No code provided'}), 400

#     code = request.json['code']
#     predicted_class = detect_vulnerability(code)
    
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe'
#     })

# if __name__ == '__main__':
#     app.run(debug=True)






##october  - graphcodebert
# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForMaskedLM
# import torch

# # Initialize the Flask application
# app = Flask(__name__)

# # Load the model and tokenizer
# tokenizer = AutoTokenizer.from_pretrained("microsoft/graphcodebert-base")
# model = AutoModelForMaskedLM.from_pretrained("microsoft/graphcodebert-base")

# @app.route('/')
# def home():
#     return "<h1>Vulnerability Detection API</h1><p>Use POST /detect to analyze code snippets.</p>"

# @app.route('/detect', methods=['POST'])
# def detect_vulnerability():
#     # Get the code snippet from the request
#     data = request.get_json()
#     code_snippet = data.get('code', '')

#     # Tokenize the input code snippet
#     inputs = tokenizer(code_snippet, return_tensors='pt')

#     # Make predictions
#     with torch.no_grad():
#         outputs = model(**inputs)
    
#     # Get logits and convert them to predicted token IDs
#     logits = outputs.logits
#     predicted_ids = logits.argmax(dim=-1).tolist()[0]  # Get predicted token IDs

#     # Decode predicted token IDs back to words
#     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_ids)

#     # Return a response with decoded tokens
#     return jsonify({
#         'code': code_snippet,
#         'predicted_tokens': predicted_tokens,
#         'predicted_ids': predicted_ids  # You can keep this for debugging if needed
#     })

# if __name__ == '__main__':
#     app.run(debug=True)


# ## october--astra
# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForCausalLM
# import torch
# from peft import PeftModel, PeftConfig

# # Initialize Flask application
# app = Flask(__name__)

# # Load the CodeAstra-7B model and tokenizer
# peft_model_id = "rootxhacker/CodeAstra-7B"
# config = PeftConfig.from_pretrained(peft_model_id)
# model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_4bit=True, device_map='auto')
# tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)

# # Load the Lora model
# model = PeftModel.from_pretrained(model, peft_model_id)

# # Disable gradient calculation for inference
# torch.no_grad()

# def detect_vulnerability(code):
#     """
#     Detects vulnerabilities in the given code using the CodeAstra-7B model.

#     Args:
#         code (str): The code snippet to analyze.

#     Returns:
#         str: The analysis result from the model.
#     """
#     # Prepare input for the model
#     query = f"Analyze this code for vulnerabilities and quality issues:\n{code}"
#     inputs = tokenizer(query, return_tensors="pt")

#     # Get model predictions
#     outputs = model.generate(**inputs, max_new_tokens=512, do_sample=True, temperature=0.7)
    
#     # Decode the output to get human-readable text
#     result = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
#     return result

# @app.route('/detect_vulnerability', methods=['POST'])
# def detect():
#     """
#     Endpoint to detect vulnerabilities in a given code snippet.

#     Returns:
#         JSON response indicating the analysis result.
#     """
#     # Check if 'code' is present in the request
#     if 'code' not in request.json:
#         return jsonify({'error': 'No code provided'}), 400

#     code = request.json['code']
    
#     # Detect vulnerability using the model
#     analysis_result = detect_vulnerability(code)
    
#     # Return the result as JSON
#     return jsonify({
#         'analysis': analysis_result
#     })

# if __name__ == '__main__':
#     app.run(debug=True)






##icober
# from flask import Flask, request, jsonify
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch

# # Initialize Flask application
# app = Flask(__name__)

# # Load the GraphCodeBERT model and tokenizer
# model_name = "microsoft/graphcodebert-base"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForSequenceClassification.from_pretrained(model_name)

# # Disable gradient calculation for inference
# torch.no_grad()

# def detect_vulnerability(code):
#     """
#     Detects if the given code is vulnerable or safe using GraphCodeBERT.

#     Args:
#         code (str): The code snippet to analyze.

#     Returns:
#         int: Predicted class (0: Safe, 1: Vulnerable).
#     """
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)

#     # Get model predictions
#     outputs = model(**inputs)
#     logits = outputs.logits

#     # Get predicted class (assuming binary classification)
#     predicted_class = torch.argmax(logits, dim=1).item()

#     return predicted_class

# @app.route('/detect_vulnerability', methods=['POST'])
# def detect():
#     """
#     Endpoint to detect vulnerability in a given code snippet.

#     Returns:
#         JSON response indicating if the code is vulnerable or safe.
#     """
#     # Check if 'code' is present in the request
#     if 'code' not in request.json:
#         return jsonify({'error': 'No code provided'}), 400

#     code = request.json['code']
    
#     # Detect vulnerability using GraphCodeBERT
#     predicted_class = detect_vulnerability(code)
    
#     # Return the result as JSON
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe'
#     })

# if __name__ == '__main__':
#     app.run(debug=True)




## xss cross scripting
# from flask import Flask, request, jsonify
# import tensorflow as tf
# import numpy as np
# import logging
# import cv2

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the trained Keras model
# model = tf.keras.models.load_model("C:/Users/ygnan/Desktop/final_model_2.h5")

# # Preprocessing function to convert sentences to ASCII and reshape them for model input
# def convert_to_ascii(sentence):
#     sentence_ascii = []

#     for i in sentence:
#         if ord(i) < 8222:
#             if ord(i) == 8221:
#                 sentence_ascii.append(129)
#             elif ord(i) == 8220:
#                 sentence_ascii.append(130)
#             elif ord(i) == 8216:
#                 sentence_ascii.append(131)
#             elif ord(i) == 8217:
#                 sentence_ascii.append(132)
#             elif ord(i) == 8211:
#                 sentence_ascii.append(133)
#             elif ord(i) <= 128:
#                 sentence_ascii.append(ord(i))
#             else:
#                 sentence_ascii.append(134)

#     # Create a 100x100 matrix and populate it with ASCII values
#     zer = np.zeros((10000))
#     for i in range(len(sentence_ascii)):
#         zer[i] = sentence_ascii[i]
#     zer = zer.reshape(100, 100)

#     # Resize and normalize
#     image = cv2.resize(zer, (100, 100), interpolation=cv2.INTER_CUBIC)
#     image /= 128.0
#     return image.reshape(1, 100, 100, 1)  # Reshape to match model input shape

# # Prediction function
# def predict_vulnerability(sentence):
#     # Preprocess the sentence
#     processed_sentence = convert_to_ascii(sentence)
    
#     # Get the model prediction
#     prediction = model.predict(processed_sentence)
    
#     # Determine class based on prediction threshold
#     predicted_class = int(prediction[0][0] > 0.5)
    
#     return 'Vulnerable' if predicted_class == 1 else 'Safe', float(prediction[0][0])

# # Define API route for prediction
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if 'code' is provided in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get prediction
#     vulnerability, probability = predict_vulnerability(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted vulnerability: {vulnerability}, Probability: {probability}')
    
#     # Return result
#     return jsonify({
#         'vulnerability': vulnerability,
#         'probability': probability
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)



##############--------------FIXING SUGGESTIONS-------------------------####################3
# from flask import Flask, request, jsonify
# from transformers import MobileBertTokenizer, MobileBertForSequenceClassification
# import torch
# import logging

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained MobileBERT model and tokenizer
# model_name = "cssupport/mobilebert-sql-injection-detect"
# tokenizer = MobileBertTokenizer.from_pretrained(model_name)
# model = MobileBertForSequenceClassification.from_pretrained(model_name)

# # Move the model to evaluation mode
# model.eval()

# # Function to predict SQL injection and suggest fixes
# def predict_sql_injection(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     with torch.no_grad():
#         outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     # Suggest fix if vulnerable
#     if predicted_class == 1:
#         fix_suggestion = "Use parameterized queries or prepared statements to avoid SQL injection."
#     else:
#         fix_suggestion = None
    
#     return predicted_class, probabilities[0].tolist(), fix_suggestion

# # Define the API route for prediction
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction from the model
#     predicted_class, probabilities, fix_suggestion = predict_sql_injection(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities,
#         'fix_suggestion': fix_suggestion
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)



##############               CORRECTING                       ###################33
# from flask import Flask, request, jsonify
# from transformers import MobileBertTokenizer, MobileBertForSequenceClassification
# import torch
# import logging
# import re

# # Initialize Flask app
# app = Flask(__name__)

# # Set up logging
# logging.basicConfig(level=logging.INFO)

# # Load the pretrained MobileBERT model and tokenizer
# model_name = "cssupport/mobilebert-sql-injection-detect"
# tokenizer = MobileBertTokenizer.from_pretrained(model_name)
# model = MobileBertForSequenceClassification.from_pretrained(model_name)

# # Move the model to evaluation mode
# model.eval()

# # Function to predict SQL injection and suggest/fix vulnerabilities
# def predict_sql_injection(code):
#     # Tokenize the input code
#     inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
#     # Run the inputs through the model
#     with torch.no_grad():
#         outputs = model(**inputs)
    
#     # Get the logits
#     logits = outputs.logits
    
#     # Convert logits to probabilities using softmax
#     probabilities = torch.softmax(logits, dim=1)
    
#     # Get the predicted class (0: Safe, 1: Vulnerable)
#     predicted_class = torch.argmax(probabilities, dim=1).item()
    
#     # If the code is vulnerable, suggest a fix
#     if predicted_class == 1:
#         fix_suggestion = "Use parameterized queries or prepared statements to avoid SQL injection."
        
#         # Apply fix to the vulnerable code
#         fixed_code = apply_parameterized_query_fix(code)
#     else:
#         fix_suggestion = None
#         fixed_code = code
    
#     return predicted_class, probabilities[0].tolist(), fix_suggestion, fixed_code

# def apply_parameterized_query_fix(code):
#     # Regular expression to detect SQL queries with string concatenation
#     pattern = re.compile(r"(\w+\s*=\s*)'(\w+)'\s*AND\s*(\w+\s*=\s*)'(\w+)'")
    
#     # Replace vulnerable code with parameterized query
#     fixed_code = re.sub(pattern, r"\1%s AND \3%s", code)
    
#     # You can extend this regex to handle more complex cases, but this is a basic example
#     return fixed_code

# # Define the API route for prediction
# @app.route('/predict', methods=['POST'])
# def predict():
#     # Check if the code is provided in the request
#     if 'code' not in request.json:
#         logging.error('No code provided in the request')
#         return jsonify({'error': 'No code provided'}), 400
    
#     # Get the code from the request
#     code = request.json['code']
#     logging.info(f'Received code for prediction: {code}')
    
#     # Get the prediction from the model and the fix suggestion
#     predicted_class, probabilities, fix_suggestion, fixed_code = predict_sql_injection(code)
    
#     # Log the prediction result
#     logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
#     # Define vulnerability classes (0 for safe, 1 for vulnerable)
#     return jsonify({
#         'vulnerability': 'Vulnerable' if predicted_class == 1 else 'Safe',
#         'probabilities': probabilities,
#         'fix_suggestion': fix_suggestion,
#         'fixed_code': fixed_code
#     })

# # Run the app
# if __name__ == "__main__":
#     app.run(debug=True)




#########          ALL EXAMPLES  ################3
from flask import Flask, request, jsonify
from transformers import MobileBertTokenizer, MobileBertForSequenceClassification
import torch
import logging
import re

# Initialize Flask app
app = Flask(__name__)

# Set up logging
logging.basicConfig(level=logging.INFO)

# Load the pretrained MobileBERT model and tokenizer
model_name = "cssupport/mobilebert-sql-injection-detect"  # Replace with your fine-tuned model
tokenizer = MobileBertTokenizer.from_pretrained(model_name)
model = MobileBertForSequenceClassification.from_pretrained(model_name)

# Move the model to evaluation mode
model.eval()

# Function to detect SQL injection vulnerabilities in code using the model
def detect_sql_injection(code):
    # Tokenize the input code
    inputs = tokenizer(code, return_tensors="pt", padding=True, truncation=True, max_length=512)
    
    # Run the inputs through the model
    with torch.no_grad():
        outputs = model(**inputs)
    
    # Get the logits
    logits = outputs.logits
    
    # Convert logits to probabilities using softmax
    probabilities = torch.softmax(logits, dim=1)
    
    # Get the predicted class (0: Safe, 1: Vulnerable)
    predicted_class = torch.argmax(probabilities, dim=1).item()

    return predicted_class, probabilities[0].tolist()

# Function to apply the fix for SQL injection vulnerabilities
def fix_sql_injection(code):
    # Apply fixes based on common SQL injection patterns using model-based detection
    # Replace direct user input with parameterized queries
    fixed_code = re.sub(r"(\w+)\s*=\s*'(.*?)'", r"\1 = ?", code)
    fixed_code = re.sub(r"\bSELECT\b.*\bFROM\b.*\bWHERE\b", r"SELECT * FROM users WHERE username = ?", fixed_code)
    fixed_code = re.sub(r"\bOR\s*1\s*=\s*1", '', fixed_code)  # Removing tautology-based injections
    fixed_code = re.sub(r"\bUNION\s+SELECT", '', fixed_code)  # Removing UNION-based injections
    fixed_code = re.sub(r"\bDROP\s+TABLE", '', fixed_code)  # Removing DROP TABLE injections
    fixed_code = re.sub(r"\bSLEEP\(", '', fixed_code)  # Removing time-based injections
    fixed_code = re.sub(r"'.*--", '', fixed_code)  # Removing comment-based injections
    
    return fixed_code

# Define the API route for prediction
@app.route('/predict', methods=['POST'])
def predict():
    # Check if the code is provided in the request
    if 'code' not in request.json:
        logging.error('No code provided in the request')
        return jsonify({'error': 'No code provided'}), 400
    
    # Get the code from the request
    code = request.json['code']
    logging.info(f'Received code for prediction: {code}')
    
    # Detect SQL injection using the model
    predicted_class, probabilities = detect_sql_injection(code)
    
    # Define vulnerability classes (0 for safe, 1 for vulnerable)
    if predicted_class == 1:
        vulnerability_status = 'Vulnerable'
        fixed_code = fix_sql_injection(code)  # Apply automatic fix for vulnerability
    else:
        vulnerability_status = 'Safe'
        fixed_code = code
    
    # Log the prediction result
    logging.info(f'Predicted class: {predicted_class}, Probabilities: {probabilities}')
    
    # Return response with vulnerability status and fixed code
    return jsonify({
        'vulnerability': vulnerability_status,
        'probabilities': probabilities,
        'fixed_code': fixed_code
    })

# Run the app
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000, debug=True)



